{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qubydev/VibeVoice/blob/main/demo/VibeVoice_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WvIaUJD2y0yU",
      "metadata": {
        "id": "WvIaUJD2y0yU"
      },
      "source": [
        "# VibeVoice Colab ‚Äî T4 Quickstart (1.5B)\n",
        "\n",
        "This notebook provides a quickstart guide to run VibeVoice on Colab with T4. The T4 GPU can only support the 1.5B model due to memory limitations. Please note that T4 can only use SDPA instead of flash_attention_2, which may result in unstable and lower audio quality. For the best TTS experience, we recommend trying the 7B model on a more powerful GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fTKYGx7DZk",
      "metadata": {
        "id": "e8fTKYGx7DZk"
      },
      "source": [
        "## Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4wxJ6QHM-ZOb",
      "metadata": {
        "id": "4wxJ6QHM-ZOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68e4f22-c583-4d9a-96a0-f2a258a72551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T4 GPU detected\n",
            "‚úÖ Cloned VibeVoice repository\n",
            "‚úÖ Installed dependencies\n",
            "‚úÖ Downloaded model: microsoft/VibeVoice-1.5B\n"
          ]
        }
      ],
      "source": [
        "# Check for T4 GPU\n",
        "import torch\n",
        "if torch.cuda.is_available() and \"T4\" in torch.cuda.get_device_name(0):\n",
        "    print(\"‚úÖ T4 GPU detected\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "    ‚ö†Ô∏è WARNING: T4 GPU not detected\n",
        "\n",
        "    The recommended runtime for this Colab notebook is \"T4 GPU\".\n",
        "\n",
        "    To change the runtime type:\n",
        "\n",
        "        1. Click on \"Runtime\" in the top navigation menu\n",
        "        2. Click on \"Change runtime type\"\n",
        "        3. Select \"T4 GPU\"\n",
        "        4. Click \"OK\" if a \"Disconnect and delete runtime\" window appears\n",
        "        5. Click on \"Save\"\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "# Clone the VibeVoice repository\n",
        "![ -d /content/VibeVoice ] || git clone --quiet --branch main --depth 1 https://github.com/vibevoice-community/VibeVoice.git /content/VibeVoice\n",
        "print(\"‚úÖ Cloned VibeVoice repository\")\n",
        "\n",
        "# Install project dependencies\n",
        "!uv pip --quiet install --system -e /content/VibeVoice\n",
        "print(\"‚úÖ Installed dependencies\")\n",
        "\n",
        "# Download model (~3 minutes)\n",
        "!HF_XET_HIGH_PERFORMANCE=1 hf download microsoft/VibeVoice-1.5B --quiet  --local-dir /content/models/VibeVoice-1.5B > /dev/null\n",
        "print(\"‚úÖ Downloaded model: microsoft/VibeVoice-1.5B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pgKlV7153Ifi",
      "metadata": {
        "id": "pgKlV7153Ifi"
      },
      "source": [
        "## Step 2: Create Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Yc1N9EHswFxA",
      "metadata": {
        "id": "Yc1N9EHswFxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81040a91-792e-4b5e-ee9b-664f429489ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/my_transcript.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/my_transcript.txt\n",
        "Speaker 1: Can I try VibeVoice with my own example?\n",
        "Speaker 2: Of course! VibeVoice is open-source, built to benefit everyone - you're welcome to try it out.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MBCC6s-F6_hP",
      "metadata": {
        "id": "MBCC6s-F6_hP"
      },
      "source": [
        "## Step 3: Generate Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYWsLJ-n0Npm",
      "metadata": {
        "id": "dYWsLJ-n0Npm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6936d27c-abb8-491e-e619-cb43efe8cd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-05 11:01:30.341336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762340490.361608    2280 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762340490.368191    2280 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762340490.383295    2280 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762340490.383328    2280 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762340490.383332    2280 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762340490.383335    2280 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 11:01:30.387970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:vibevoice.modular.modular_vibevoice_tokenizer:APEX FusedRMSNorm not available, using native implementation\n",
            "üéôÔ∏è Initializing VibeVoice Demo with Streaming Support...\n",
            "Loading processor & model from /content/models/VibeVoice-1.5B\n",
            "Using device: cuda\n",
            "tokenizer_config.json: 7.23kB [00:00, 29.6MB/s]\n",
            "vocab.json: 2.78MB [00:00, 60.1MB/s]\n",
            "merges.txt: 1.67MB [00:00, 127MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 186MB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'. \n",
            "The class this function is called from is 'VibeVoiceTextTokenizerFast'.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Using device: cuda, torch_dtype: torch.bfloat16, attn_implementation: flash_attention_2\n",
            "loading configuration file /content/models/VibeVoice-1.5B/config.json\n",
            "Model config VibeVoiceConfig {\n",
            "  \"acoustic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"decoder_depths\": null,\n",
            "    \"decoder_n_filters\": 32,\n",
            "    \"decoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0.5,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_acoustic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"gaussian\",\n",
            "    \"vae_dim\": 64,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"acoustic_vae_dim\": 64,\n",
            "  \"architectures\": [\n",
            "    \"VibeVoiceForConditionalGeneration\"\n",
            "  ],\n",
            "  \"decoder_config\": {\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 1536,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 8960,\n",
            "    \"max_position_embeddings\": 65536,\n",
            "    \"max_window_layers\": 28,\n",
            "    \"model_type\": \"qwen2\",\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_hidden_layers\": 28,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": null,\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sliding_window\": null,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"vocab_size\": 151936\n",
            "  },\n",
            "  \"diffusion_head_config\": {\n",
            "    \"ddpm_batch_mul\": 4,\n",
            "    \"ddpm_beta_schedule\": \"cosine\",\n",
            "    \"ddpm_num_inference_steps\": 20,\n",
            "    \"ddpm_num_steps\": 1000,\n",
            "    \"diffusion_type\": \"ddpm\",\n",
            "    \"head_ffn_ratio\": 3.0,\n",
            "    \"head_layers\": 4,\n",
            "    \"hidden_size\": 1536,\n",
            "    \"latent_size\": 64,\n",
            "    \"model_type\": \"vibevoice_diffusion_head\",\n",
            "    \"prediction_type\": \"v_prediction\",\n",
            "    \"rms_norm_eps\": 1e-05,\n",
            "    \"speech_vae_dim\": 64\n",
            "  },\n",
            "  \"model_type\": \"vibevoice\",\n",
            "  \"semantic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_semantic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"none\",\n",
            "    \"vae_dim\": 128,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"semantic_vae_dim\": 128,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "loading weights file /content/models/VibeVoice-1.5B/model.safetensors.index.json\n",
            "Instantiating VibeVoiceForConditionalGenerationInference model under default dtype torch.bfloat16.\n",
            "[ERROR] : ImportError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/./VibeVoice/demo/gradio_demo.py\", line 86, in load_model\n",
            "    self.model = VibeVoiceForConditionalGenerationInference.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4336, in from_pretrained\n",
            "    config = cls._autoset_attn_implementation(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 2109, in _autoset_attn_implementation\n",
            "    cls._check_and_enable_flash_attn_2(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 2252, in _check_and_enable_flash_attn_2\n",
            "    raise ImportError(f\"{preface} the package flash_attn seems to be not installed. {install_message}\")\n",
            "ImportError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\n",
            "\n",
            "Falling back to attention implementation: sdpa\n",
            "loading configuration file /content/models/VibeVoice-1.5B/config.json\n",
            "Model config VibeVoiceConfig {\n",
            "  \"acoustic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"decoder_depths\": null,\n",
            "    \"decoder_n_filters\": 32,\n",
            "    \"decoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0.5,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_acoustic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"gaussian\",\n",
            "    \"vae_dim\": 64,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"acoustic_vae_dim\": 64,\n",
            "  \"architectures\": [\n",
            "    \"VibeVoiceForConditionalGeneration\"\n",
            "  ],\n",
            "  \"decoder_config\": {\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 1536,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 8960,\n",
            "    \"max_position_embeddings\": 65536,\n",
            "    \"max_window_layers\": 28,\n",
            "    \"model_type\": \"qwen2\",\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_hidden_layers\": 28,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": null,\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sliding_window\": null,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"vocab_size\": 151936\n",
            "  },\n",
            "  \"diffusion_head_config\": {\n",
            "    \"ddpm_batch_mul\": 4,\n",
            "    \"ddpm_beta_schedule\": \"cosine\",\n",
            "    \"ddpm_num_inference_steps\": 20,\n",
            "    \"ddpm_num_steps\": 1000,\n",
            "    \"diffusion_type\": \"ddpm\",\n",
            "    \"head_ffn_ratio\": 3.0,\n",
            "    \"head_layers\": 4,\n",
            "    \"hidden_size\": 1536,\n",
            "    \"latent_size\": 64,\n",
            "    \"model_type\": \"vibevoice_diffusion_head\",\n",
            "    \"prediction_type\": \"v_prediction\",\n",
            "    \"rms_norm_eps\": 1e-05,\n",
            "    \"speech_vae_dim\": 64\n",
            "  },\n",
            "  \"model_type\": \"vibevoice\",\n",
            "  \"semantic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_semantic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"none\",\n",
            "    \"vae_dim\": 128,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"semantic_vae_dim\": 128,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "loading weights file /content/models/VibeVoice-1.5B/model.safetensors.index.json\n",
            "Instantiating VibeVoiceForConditionalGenerationInference model under default dtype torch.bfloat16.\n",
            "Generate config GenerationConfig {}\n",
            "\n",
            "Instantiating Qwen2Model model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceAcousticTokenizerModel model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceSemanticTokenizerModel model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceDiffusionHead model under default dtype torch.bfloat16.\n",
            "Loading checkpoint shards: 100% 3/3 [00:15<00:00,  5.01s/it]\n",
            "All model checkpoint weights were used when initializing VibeVoiceForConditionalGenerationInference.\n",
            "\n",
            "All the weights of VibeVoiceForConditionalGenerationInference were initialized from the model checkpoint at /content/models/VibeVoice-1.5B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use VibeVoiceForConditionalGenerationInference for predictions without further training.\n",
            "Generation config file not found, using a generation config created from the model config.\n",
            "Language model attention: sdpa\n",
            "Found 9 voice files in /content/./VibeVoice/demo/voices\n",
            "Available voices: en-Alice_woman, en-Carter_man, en-Frank_man, en-Mary_woman_bgm, en-Maya_woman, in-Samuel_man, zh-Anchen_man_bgm, zh-Bowen_man, zh-Xinran_woman\n",
            "Loaded example: 1p_Ch2EN.txt with 1 speakers\n",
            "Loaded example: 1p_abs.txt with 1 speakers\n",
            "Loaded example: 2p_goat.txt with 2 speakers\n",
            "Loaded example: 2p_music.txt with 2 speakers\n",
            "Loaded example: 2p_short.txt with 2 speakers\n",
            "Loaded example: 2p_yayi.txt with 2 speakers\n",
            "Loaded example: 3p_gpt5.txt with 3 speakers\n",
            "Skipping 4p_climate_100min.txt: duration 100 minutes exceeds 15-minute limit\n",
            "Skipping 4p_climate_45min.txt: duration 45 minutes exceeds 15-minute limit\n",
            "Successfully loaded 7 example scripts\n",
            "üöÄ Launching demo on port 7860\n",
            "üìÅ Model path: /content/models/VibeVoice-1.5B\n",
            "üé≠ Available voices: 9\n",
            "üî¥ Streaming mode: ENABLED\n",
            "üîí Session isolation: ENABLED\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://a8f495a70648cbcad6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ],
      "source": [
        "# # Run Python script to generate audio from transcript\n",
        "# !python /content/VibeVoice/demo/inference_from_file.py \\\n",
        "#     --model_path /content/models/VibeVoice-1.5B \\\n",
        "#     --txt_path /content/my_transcript.txt \\\n",
        "#     --speaker_names Alice Frank\n",
        "\n",
        "# # Display audio controls\n",
        "# from IPython.display import Audio\n",
        "# Audio(\"/content/outputs/my_transcript_generated.wav\")\n",
        "\n",
        "!python ./VibeVoice/demo/gradio_demo.py --model_path /content/models/VibeVoice-1.5B --inference_steps 10 --share\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec6438d5",
      "metadata": {
        "id": "ec6438d5"
      },
      "source": [
        "# Step 4: Download Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40ffa22",
      "metadata": {
        "id": "b40ffa22"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/outputs/my_transcript_generated.wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bce752d",
      "metadata": {
        "id": "1bce752d"
      },
      "source": [
        "\n",
        "## Risks and Limitations\n",
        "\n",
        "While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "name": "VibeVoice_Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}